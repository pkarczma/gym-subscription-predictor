{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gym_subscription_predictor.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCfIqN1uuzIW"
      },
      "source": [
        "# Executive Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_ID2t3oYtey"
      },
      "source": [
        "This report describes the approach taken to build a gym subscription prediction model based on the user data provided as an input. It consist of descriptions, as well as the code written in Python language used to process data, build a model, and obtain final results. First section of this report serves to access data, get familiar with it, clean it, and transform it for the model to read it. Second section explains which model was selected and how it was build, compiled, and fit. Next section presents model quality assessment approach. Then, it is shown how the test file was scored with the prepared model. Last two sections describe findings encountered during the process and limitations of selected approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZXrkeP7u_Ns"
      },
      "source": [
        "# Input Data and Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBBTG04EdMBF"
      },
      "source": [
        "In this section the process of analysis of the provided data is described. For this task I am going to store data in a format of so-called dataframes (DataFrame classes) from Pandas library wirtten for Python language:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKs1MxhLdFw7"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_p7j_XmsYmm"
      },
      "source": [
        "### Access data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mvKSUs_Ca3z"
      },
      "source": [
        "The data provided for this task has been uploaded in order to automatize this report. To access data I am going to clone the files that I stored in the git repository:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhctCVOi0JIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b24aa39-9edb-423e-aca4-d496c1beb75e"
      },
      "source": [
        "!git clone https://github.com/pkarczma/gym-subscription-predictor.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'gym-subscription-predictor' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPSHXrj2CeRK"
      },
      "source": [
        "Next, one needs to read it. I am going to start with the data used for training. The data consist of CSV and JSON files, which are going to be read into two dataframes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YudIQBVaw3OS"
      },
      "source": [
        "path = 'gym-subscription-predictor/'\n",
        "df_csv = pd.read_csv(path+'train.csv')\n",
        "df_json = pd.read_json(path+'train.json', orient='split').set_index('id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdZ6phmWgf0U"
      },
      "source": [
        "### Merge data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVWv0Uf9gxYz"
      },
      "source": [
        "The data for each used is split into two files: structured CSV file and unstructured JSON file. The data read from JSON file is unstructured. What we would like to achieve is one dataframe that consist of rows containing all the information about each user. To do that the data read from JSON file needs some conversion in order to extract necessary data nested inside. A new dataframe containing a list of group names for each user will be extracted. The information about the date of joining the group is skipped as this seem redundant for this task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFrNAlGxCz0P"
      },
      "source": [
        "df_groups = pd.DataFrame(columns=['groups'])\n",
        "for i in df_json.to_dict()['groups'].items():\n",
        "  groups = ''\n",
        "  for j in i[1]['data']:\n",
        "    if len(groups) > 0:\n",
        "      groups += '|'\n",
        "    groups += j['group_name']\n",
        "  df_groups = df_groups.append({'groups': groups}, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyxLBMbYiTsh"
      },
      "source": [
        "Now it is possible to merge two dataframes into one dataset containing all information about each user:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyrqtetEiXkt"
      },
      "source": [
        "df = pd.concat([df_csv, df_groups], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG1I_NrSsiLX"
      },
      "source": [
        "### Analyse and clear data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6VTw4XZCoFD"
      },
      "source": [
        "This section focuses on getting familiar with the data. One can have a look at some information about the dataframe and its columns, as well as look at the first few rows of the dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33u8oZZk_BMe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "outputId": "6f3b660a-295c-4e5c-f999-5b8b355a1184"
      },
      "source": [
        "df.info()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4000 entries, 0 to 3999\n",
            "Data columns (total 17 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   user_id                   4000 non-null   int64  \n",
            " 1   target                    4000 non-null   int64  \n",
            " 2   name                      3982 non-null   object \n",
            " 3   sex                       3616 non-null   object \n",
            " 4   dob                       3606 non-null   object \n",
            " 5   location                  4000 non-null   object \n",
            " 6   location_population       4000 non-null   int64  \n",
            " 7   location_from             4000 non-null   object \n",
            " 8   location_from_population  4000 non-null   int64  \n",
            " 9   occupation                4000 non-null   object \n",
            " 10  hobbies                   3320 non-null   object \n",
            " 11  daily_commute             3595 non-null   float64\n",
            " 12  friends_number            4000 non-null   int64  \n",
            " 13  relationship_status       3607 non-null   object \n",
            " 14  education                 3592 non-null   float64\n",
            " 15  credit_card_type          3572 non-null   object \n",
            " 16  groups                    4000 non-null   object \n",
            "dtypes: float64(2), int64(5), object(10)\n",
            "memory usage: 531.4+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>target</th>\n",
              "      <th>name</th>\n",
              "      <th>sex</th>\n",
              "      <th>dob</th>\n",
              "      <th>location</th>\n",
              "      <th>location_population</th>\n",
              "      <th>location_from</th>\n",
              "      <th>location_from_population</th>\n",
              "      <th>occupation</th>\n",
              "      <th>hobbies</th>\n",
              "      <th>daily_commute</th>\n",
              "      <th>friends_number</th>\n",
              "      <th>relationship_status</th>\n",
              "      <th>education</th>\n",
              "      <th>credit_card_type</th>\n",
              "      <th>groups</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Halina</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1982-08-07</td>\n",
              "      <td>Piastów</td>\n",
              "      <td>22732</td>\n",
              "      <td>Piastów</td>\n",
              "      <td>22732</td>\n",
              "      <td>Teaching professionals</td>\n",
              "      <td>Fitness</td>\n",
              "      <td>46.0</td>\n",
              "      <td>196</td>\n",
              "      <td>Single</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Visa</td>\n",
              "      <td>Let's excercise together and lose a few kilo q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Eustachy</td>\n",
              "      <td>male</td>\n",
              "      <td>1971-10-28</td>\n",
              "      <td>Sokółka</td>\n",
              "      <td>18331</td>\n",
              "      <td>Sokółka</td>\n",
              "      <td>18331</td>\n",
              "      <td>General and keyboard clerks</td>\n",
              "      <td>LARPing,Foreign language learning,Netball</td>\n",
              "      <td>55.0</td>\n",
              "      <td>243</td>\n",
              "      <td>Single</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tom Cruise group|Babysitters (Sokółka)|Work ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Egon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000-07-05</td>\n",
              "      <td>Łaskarzew</td>\n",
              "      <td>4879</td>\n",
              "      <td>Łaskarzew</td>\n",
              "      <td>4879</td>\n",
              "      <td>Protective services workers</td>\n",
              "      <td>Bodybuilding,Kabaddi</td>\n",
              "      <td>90.0</td>\n",
              "      <td>191</td>\n",
              "      <td>In relationship</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Polish wildlife - best places|Politics and pol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Eulalia</td>\n",
              "      <td>female</td>\n",
              "      <td>1992-06-10</td>\n",
              "      <td>Bydgoszcz</td>\n",
              "      <td>352313</td>\n",
              "      <td>Bydgoszcz</td>\n",
              "      <td>352313</td>\n",
              "      <td>Customer services clerks</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>88.0</td>\n",
              "      <td>164</td>\n",
              "      <td>In relationship</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Visa</td>\n",
              "      <td>The Aspiring Writer|Nutrition &amp; food advices|G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Hilary</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1975-01-09</td>\n",
              "      <td>Osieczna</td>\n",
              "      <td>2322</td>\n",
              "      <td>Poznań</td>\n",
              "      <td>538633</td>\n",
              "      <td>Refuse workers and other elementary workers</td>\n",
              "      <td>Fitness,Embroidery,Lacemaking</td>\n",
              "      <td>40.0</td>\n",
              "      <td>119</td>\n",
              "      <td>Married with kids</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The ultimate house and electro group|Pirates o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  ...                                             groups\n",
              "0        0  ...  Let's excercise together and lose a few kilo q...\n",
              "1        1  ...  Tom Cruise group|Babysitters (Sokółka)|Work ab...\n",
              "2        2  ...  Polish wildlife - best places|Politics and pol...\n",
              "3        3  ...  The Aspiring Writer|Nutrition & food advices|G...\n",
              "4        4  ...  The ultimate house and electro group|Pirates o...\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1ED8BDNPkGK"
      },
      "source": [
        "This overview enables extraction of many useful information. There are 4000 users and 16 columns describing each user. There are some columns with empty cells, but it will be dealt with later. At this point it would be useful to evaluate which part of the data isn't necessary for the model. It is going to be assumed that the following columns are not indicating an initial interest in gym subscription:\n",
        "* name\n",
        "* location_population\n",
        "* location_from_population\n",
        "* daily_commute\n",
        "* credit_card_type\n",
        "\n",
        "As a result I am going to drop them from the dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Var-YiBKPAwQ"
      },
      "source": [
        "df = df.drop(columns=['name', 'location_population', 'location_from_population', 'daily_commute', 'credit_card_type'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NM9TAI6EPtI"
      },
      "source": [
        "Afterwards, one can focus on the missing values that are still in the remaining data. It is useful to count the number of missing values in each of the remaining columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ4C8MHODTMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86dbd1c3-11f0-4574-be2a-0d454f940d18"
      },
      "source": [
        "df.isnull().sum(axis = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user_id                  0\n",
              "target                   0\n",
              "sex                    384\n",
              "dob                    394\n",
              "location                 0\n",
              "location_from            0\n",
              "occupation               0\n",
              "hobbies                680\n",
              "friends_number           0\n",
              "relationship_status    393\n",
              "education              408\n",
              "groups                   0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYdofSPOC8dM"
      },
      "source": [
        "There are still some missing values in data in several columns. I am going to use a different approach depending on the column with the missing values. The following procedure will be applied:\n",
        "* 'user_id' / 'target' / 'location' / 'location_from' / 'occupation' / 'friends_number': no missing values, columns are useful, nothing changes\n",
        "* 'education': fill missing values with a median of a column\n",
        "* 'hobbies': I assume that empty value means that a user has no hobbies, so I will fill missing values with empty string\n",
        "\n",
        "For the remaining data with missing values it is problematic to deduce how replace it. One can also notice that the fraction of missing values to all values isn't too large - it is around 10% for each of the remaining columns with missing values. Consequently, the rows with at least one missing calue will be dropped from the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAcLq_a0_Rtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb6838da-ac14-4e5a-c822-064bdcb10836"
      },
      "source": [
        "df['hobbies'] = df['hobbies'].fillna('')\n",
        "df['education'] = df['education'].fillna(df['education'].median())\n",
        "df = df.dropna()\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2945 entries, 1 to 3999\n",
            "Data columns (total 12 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   user_id              2945 non-null   int64  \n",
            " 1   target               2945 non-null   int64  \n",
            " 2   sex                  2945 non-null   object \n",
            " 3   dob                  2945 non-null   object \n",
            " 4   location             2945 non-null   object \n",
            " 5   location_from        2945 non-null   object \n",
            " 6   occupation           2945 non-null   object \n",
            " 7   hobbies              2945 non-null   object \n",
            " 8   friends_number       2945 non-null   int64  \n",
            " 9   relationship_status  2945 non-null   object \n",
            " 10  education            2945 non-null   float64\n",
            " 11  groups               2945 non-null   object \n",
            "dtypes: float64(1), int64(3), object(8)\n",
            "memory usage: 299.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDV-Kfvpk8Dj"
      },
      "source": [
        "As a result, around 25% of all rows were removed and there are 2945 users left. I assume that this is a sufficient number of entries for the model. Now the data is clean and ready for the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDtd4CLXr5T0"
      },
      "source": [
        "### Transform data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys5LNwLGsE-B"
      },
      "source": [
        "In order to prepare data for the model a convertion to the proper format is needed. The following code will convert non-numeric data to categories so that is it easier for the model to read it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhnHh-uOtLFq"
      },
      "source": [
        "df['sex'] = df['sex'].astype('category').cat.codes\n",
        "df['location'] = df['location'].astype('category').cat.codes\n",
        "df['location_from'] = df['location_from'].astype('category').cat.codes\n",
        "df['occupation'] = df['occupation'].astype('category').cat.codes\n",
        "df['relationship_status'] = df['relationship_status'].astype('category').cat.codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nbhk_WEBLkyK"
      },
      "source": [
        "For the date of birth, I assume there is no need to keep the exact date - having just a year of birth should be enough for the model. I will drop the day and month information from 'dob' column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnV7mBe_L1YY"
      },
      "source": [
        "df['dob'] = pd.DatetimeIndex(df['dob']).year"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ybXqKhru2E0"
      },
      "source": [
        "For the 'hobbies' column the best way is to extract dummies for each row and split it into columns with values of 0 or 1 indicating interest (or lack of interest) in a particular hobby. An additional 'hobby_' prefix will indicate that this column represents a hobby, but also to make sure that none of the column names are overlapping with the rest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsfVaCK7pJwi"
      },
      "source": [
        "df = pd.concat([df.drop('hobbies', axis=1), df['hobbies'].str.get_dummies(sep=',').add_prefix('hobby_')], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwtaiam9EFXz"
      },
      "source": [
        "I am going to apply a similar procedure to the 'groups' column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3Zq8C8HEMEA"
      },
      "source": [
        "df = pd.concat([df.drop('groups', axis=1), df['groups'].str.get_dummies(sep='|').add_prefix('group_')], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEBuPt4fvZoZ"
      },
      "source": [
        "At this point the data contains only numbers, there are no missing values, and it is prepared for the next step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KuLSWfovvSj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "9bb383e3-412e-4494-819e-7d711a07cca8"
      },
      "source": [
        "df.info()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2945 entries, 1 to 3999\n",
            "Columns: 3521 entries, user_id to group_muscle, strength  and vascularity - What every bodybuilder should know\n",
            "dtypes: float64(1), int16(2), int64(3515), int8(3)\n",
            "memory usage: 79.0 MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>target</th>\n",
              "      <th>sex</th>\n",
              "      <th>dob</th>\n",
              "      <th>location</th>\n",
              "      <th>location_from</th>\n",
              "      <th>occupation</th>\n",
              "      <th>friends_number</th>\n",
              "      <th>relationship_status</th>\n",
              "      <th>education</th>\n",
              "      <th>hobby_3D printing</th>\n",
              "      <th>hobby_Acting</th>\n",
              "      <th>hobby_Air sports</th>\n",
              "      <th>hobby_Amateur radio</th>\n",
              "      <th>hobby_Archery</th>\n",
              "      <th>hobby_Astronomy</th>\n",
              "      <th>hobby_BASE jumping</th>\n",
              "      <th>hobby_Backpacking</th>\n",
              "      <th>hobby_Badminton</th>\n",
              "      <th>hobby_Baseball</th>\n",
              "      <th>hobby_Basketball</th>\n",
              "      <th>hobby_Beekeeping</th>\n",
              "      <th>hobby_Bird watching</th>\n",
              "      <th>hobby_Blacksmithing</th>\n",
              "      <th>hobby_Board games</th>\n",
              "      <th>hobby_Board sports</th>\n",
              "      <th>hobby_Bodybuilding</th>\n",
              "      <th>hobby_Book restoration</th>\n",
              "      <th>hobby_Brazilian jiu-jitsu</th>\n",
              "      <th>hobby_Cabaret</th>\n",
              "      <th>hobby_Calligraphy</th>\n",
              "      <th>hobby_Candle making</th>\n",
              "      <th>hobby_Cardio</th>\n",
              "      <th>hobby_Coffee roasting</th>\n",
              "      <th>hobby_Coloring</th>\n",
              "      <th>hobby_Community</th>\n",
              "      <th>hobby_Computer programming</th>\n",
              "      <th>hobby_Cooking</th>\n",
              "      <th>hobby_Cosplaying</th>\n",
              "      <th>hobby_Creative writing</th>\n",
              "      <th>...</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Sopot)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Sosnowiec)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Swarzędz)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Szczecin)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Słubice)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Słupsk)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Tarnów)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Tczew)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Terespol)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Tomaszów Mazowiecki)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Toruń)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Tuchola)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Tychy)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Warszawa)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Warta)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Wasilków)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Wolbrom)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Wrocław)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Włocławek)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Zabrze)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Zator)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Zduńska Wola)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Zielona Góra)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Ząbki)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Łomża)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Łódź)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Śrem)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Świdnik)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Świętochłowice)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Żagań)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Żary)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Żyrardów)</th>\n",
              "      <th>group_World Weightlifting Championships</th>\n",
              "      <th>group_Xbox , Playstation, Wii - console fans</th>\n",
              "      <th>group_Young, fit and healthy - active livestyle = healthy lifestyle.</th>\n",
              "      <th>group_ZTM Warsaw</th>\n",
              "      <th>group_alternative medicine - Hypnosis and bioenergotheraphy</th>\n",
              "      <th>group_ham cooker - recipes</th>\n",
              "      <th>group_instrumental music - the unheard and undiscovered</th>\n",
              "      <th>group_muscle, strength  and vascularity - What every bodybuilder should know</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1971</td>\n",
              "      <td>400</td>\n",
              "      <td>415</td>\n",
              "      <td>15</td>\n",
              "      <td>243</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1992</td>\n",
              "      <td>46</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>164</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1981</td>\n",
              "      <td>465</td>\n",
              "      <td>490</td>\n",
              "      <td>22</td>\n",
              "      <td>117</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1978</td>\n",
              "      <td>81</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>224</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1985</td>\n",
              "      <td>465</td>\n",
              "      <td>490</td>\n",
              "      <td>26</td>\n",
              "      <td>187</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3521 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  ...  group_muscle, strength  and vascularity - What every bodybuilder should know\n",
              "1        1  ...                                                  0                           \n",
              "3        3  ...                                                  0                           \n",
              "6        6  ...                                                  0                           \n",
              "7        7  ...                                                  0                           \n",
              "9        9  ...                                                  0                           \n",
              "\n",
              "[5 rows x 3521 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN7OlPw_vFjh"
      },
      "source": [
        "# Model Selection and Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9lH1fUWppzz"
      },
      "source": [
        "In this section I am going to build a model that will be used for predictions. For this task I am going to use Keras interface from the TensorFlow library, as well as some other libraries necessary for data validation and plotting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jvKQBBEqC7g"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNPSUlIUzXcf"
      },
      "source": [
        "### Split data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9Ozjnawyc97"
      },
      "source": [
        "For the model training and testing the dataset will be split into two subsets:\n",
        "* 80% of the data will be used for training\n",
        "* 20% od the remaining data will be used for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozVIGMXCx3Og"
      },
      "source": [
        "train_dataset = df.sample(frac=0.8, random_state=0)\n",
        "test_dataset = df.drop(train_dataset.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b46_y2c4y2x7"
      },
      "source": [
        "I am going to separate labels from features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EGNKJrEzLTw"
      },
      "source": [
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()\n",
        "train_labels = train_features.pop('target')\n",
        "test_labels = test_features.pop('target')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhDAaP8uz31-"
      },
      "source": [
        "### Build model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIMu-S6Pz6Tr"
      },
      "source": [
        "Now it is time to build a model. The selected model will be a regression-based neural network consisting of several input, hidden, and output layers. It will use existing data prepared in the previous section as an input in order to create predictions of the desired variable.\n",
        "\n",
        "This model prefers to have the input data normalized in a specific way. Thus, one needs to create a normalization layer that is adapted to the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9aKQTJD22Mu"
      },
      "source": [
        "normalizer = layers.experimental.preprocessing.Normalization()\n",
        "normalizer.adapt(np.array(train_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXO3e9XE3rCj"
      },
      "source": [
        "Afterwards, one can build a fully-connected model consisting of a sequential stack of layers, where first layer is a normalization layer, then there are hidden layers using a rectified linear unit as an activation function, while the last output layer is using a sigmoid function in order to ensure that the network output is between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaaF8Rf537FB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c00bc6ec-5a48-48de-e61f-ca863e57b41f"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    normalizer,\n",
        "    layers.Dense(3520, input_dim=3520, activation='relu'),\n",
        "    layers.Dense(440, activation='relu'),\n",
        "    layers.Dense(55, activation='relu'),\n",
        "    layers.Dense(11, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization_3 (Normalizati (None, 3520)              7041      \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 3520)              12393920  \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 440)               1549240   \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 55)                24255     \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 11)                616       \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 1)                 12        \n",
            "=================================================================\n",
            "Total params: 13,975,084\n",
            "Trainable params: 13,968,043\n",
            "Non-trainable params: 7,041\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jmL5utb5kDg"
      },
      "source": [
        "### Compile and fit model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uf79bLo5IWr"
      },
      "source": [
        "Next step is to compile the model. It is necessary to specify the loss function to use for weights evaluation. As this is a binary classification problem the model is going to use 'binary_crossentropy' as a loss function. The model will be classified using the collected accuracy value. It is also going to use Adam optimization algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adPXX-CJ5S_V"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISqfsuHz5bpC"
      },
      "source": [
        "Then, one can fit the model providing different settings that can be adjusted for the model efficacy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zscy8dS56Ces"
      },
      "source": [
        "history = model.fit(\n",
        "    # Data to be used for training\n",
        "    train_features, train_labels,\n",
        "    # Number of epochs\n",
        "    epochs=5,\n",
        "    # Suppress logging\n",
        "    verbose=0,\n",
        "    # Calculate validation results on 20% of the training data\n",
        "    validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSiw_3tm6f4u"
      },
      "source": [
        "After fitting one can have a look at the last few epochs of the training of the model in order to see if everything works well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuKOm3rE6rkP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6a669aad-76ce-42e7-c16a-4bc6f25d77d6"
      },
      "source": [
        "# Show history in the last few epochs\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.468420</td>\n",
              "      <td>0.783970</td>\n",
              "      <td>0.417765</td>\n",
              "      <td>0.773305</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.189318</td>\n",
              "      <td>0.875796</td>\n",
              "      <td>0.442065</td>\n",
              "      <td>0.794492</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.061521</td>\n",
              "      <td>0.972399</td>\n",
              "      <td>0.506837</td>\n",
              "      <td>0.722458</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.017046</td>\n",
              "      <td>0.994161</td>\n",
              "      <td>0.621360</td>\n",
              "      <td>0.847458</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.006926</td>\n",
              "      <td>0.998408</td>\n",
              "      <td>0.621340</td>\n",
              "      <td>0.792373</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy  epoch\n",
              "0  0.468420  0.783970  0.417765      0.773305      0\n",
              "1  0.189318  0.875796  0.442065      0.794492      1\n",
              "2  0.061521  0.972399  0.506837      0.722458      2\n",
              "3  0.017046  0.994161  0.621360      0.847458      3\n",
              "4  0.006926  0.998408  0.621340      0.792373      4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQAyb8qnvJvn"
      },
      "source": [
        "# Model Quality Assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlPqC2saENSO"
      },
      "source": [
        "In order to assess the quality of the model I am going to use the fraction of the dataset that hasn't been provided to the model yet. One can extract a list of probabilities for each user in the test sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q1QhngttOEm"
      },
      "source": [
        "test_predictions = model.predict(test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf74onCCEk5B"
      },
      "source": [
        "Now it is possible to extract the fraction of correct prediction by comparing it to the true labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGV4JsCxEgjo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b98aa555-7234-48dd-9c87-976687178ccf"
      },
      "source": [
        "correct = sum(i == j for i, j in zip(np.around(test_predictions), test_labels))[0]\n",
        "print(correct / len(test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8590831918505942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BNc8dKRE13F"
      },
      "source": [
        "One can see that over 85% of predictions are correct. Even better way to look at the results is to create a confuction matrix showing the fraction of correct and incorrect predictions in each class (in this case it will be '0' and '1' as this is a binary classification)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFoaG3SOEh0S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "bb61278c-71e0-46e1-cb68-9ff96d283a77"
      },
      "source": [
        "cm = confusion_matrix(test_labels, np.around(test_predictions))\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Normalized confusion matrix')\n",
        "plt.colorbar()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, \"{0:0.2f}\".format(cm[i, j]),\n",
        "        horizontalalignment=\"center\",\n",
        "        color=\"white\" if cm[i, j] > thresh else \"black\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEJGv9UoFPMk"
      },
      "source": [
        "One can see that almost all labels marked as '0' are correctly identified. For labels marked as '1' the model doesn't work that well and predicts correctly only around 30% of all cases. This means that the model predicts very well who is not interested in gym subscription, but identifies only a fraction of users interested in subscription."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YTPzIsrI9uY"
      },
      "source": [
        "# Scoring Test File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtBVoPB8Jns7"
      },
      "source": [
        "In this section the model will be used to produce target variable on the data stored in test.csv and test.json files. The test files will be read and transformed in a similar way as before. I will also remove rows that are missing some data and only for the remaining rows the model will be used for predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "hJ6WlqqZKGjW",
        "outputId": "ceab8a82-d126-4acc-f48f-64003366133b"
      },
      "source": [
        "df_model = df.copy()\n",
        "df_csv = pd.read_csv(path+'test.csv')\n",
        "df_json = pd.read_json(path+'test.json', orient='split').set_index('id')\n",
        "df_groups = pd.DataFrame(columns=['groups'])\n",
        "for i in df_json.to_dict()['groups'].items():\n",
        "  groups = ''\n",
        "  for j in i[1]['data']:\n",
        "    if len(groups) > 0:\n",
        "      groups += '|'\n",
        "    groups += j['group_name']\n",
        "  df_groups = df_groups.append({'groups': groups}, ignore_index=True)\n",
        "df_groups.head()\n",
        "df = pd.concat([df_csv, df_groups], axis=1)\n",
        "df = df.drop(columns=['target', 'name', 'location_population', 'location_from_population', 'daily_commute', 'credit_card_type'])\n",
        "df['hobbies'] = df['hobbies'].fillna('')\n",
        "df['education'] = df['education'].fillna(df['education'].median())\n",
        "df = df.dropna()\n",
        "df['sex'] = df['sex'].astype('category').cat.codes\n",
        "df['location'] = df['location'].astype('category').cat.codes\n",
        "df['location_from'] = df['location_from'].astype('category').cat.codes\n",
        "df['occupation'] = df['occupation'].astype('category').cat.codes\n",
        "df['relationship_status'] = df['relationship_status'].astype('category').cat.codes\n",
        "df['dob'] = pd.DatetimeIndex(df['dob']).year\n",
        "df = pd.concat([df.drop('hobbies', axis=1), df['hobbies'].str.get_dummies(sep=',').add_prefix('hobby_')], axis=1)\n",
        "df = pd.concat([df.drop('groups', axis=1), df['groups'].str.get_dummies(sep='|').add_prefix('group_')], axis=1)\n",
        "df.info()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1452 entries, 0 to 1999\n",
            "Columns: 2176 entries, user_id to group_muscle, strength  and vascularity - What every bodybuilder should know\n",
            "dtypes: float64(1), int16(2), int64(2170), int8(3)\n",
            "memory usage: 24.1 MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>sex</th>\n",
              "      <th>dob</th>\n",
              "      <th>location</th>\n",
              "      <th>location_from</th>\n",
              "      <th>occupation</th>\n",
              "      <th>friends_number</th>\n",
              "      <th>relationship_status</th>\n",
              "      <th>education</th>\n",
              "      <th>hobby_3D printing</th>\n",
              "      <th>hobby_Acting</th>\n",
              "      <th>hobby_Air sports</th>\n",
              "      <th>hobby_Amateur radio</th>\n",
              "      <th>hobby_Archery</th>\n",
              "      <th>hobby_Astronomy</th>\n",
              "      <th>hobby_BASE jumping</th>\n",
              "      <th>hobby_Backpacking</th>\n",
              "      <th>hobby_Badminton</th>\n",
              "      <th>hobby_Baseball</th>\n",
              "      <th>hobby_Basketball</th>\n",
              "      <th>hobby_Beekeeping</th>\n",
              "      <th>hobby_Bird watching</th>\n",
              "      <th>hobby_Blacksmithing</th>\n",
              "      <th>hobby_Board games</th>\n",
              "      <th>hobby_Board sports</th>\n",
              "      <th>hobby_Bodybuilding</th>\n",
              "      <th>hobby_Book restoration</th>\n",
              "      <th>hobby_Brazilian jiu-jitsu</th>\n",
              "      <th>hobby_Cabaret</th>\n",
              "      <th>hobby_Calligraphy</th>\n",
              "      <th>hobby_Candle making</th>\n",
              "      <th>hobby_Cardio</th>\n",
              "      <th>hobby_Coffee roasting</th>\n",
              "      <th>hobby_Coloring</th>\n",
              "      <th>hobby_Community</th>\n",
              "      <th>hobby_Computer programming</th>\n",
              "      <th>hobby_Cooking</th>\n",
              "      <th>hobby_Cosplaying</th>\n",
              "      <th>hobby_Creative writing</th>\n",
              "      <th>hobby_Crocheting</th>\n",
              "      <th>...</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Poznań)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Przasnysz)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Pułtusk)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Płock)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Racibórz)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Rybnik)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Rychwał)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Siedlce)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Staszów)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Sulejówek)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Suwałki)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Swarzędz)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Szczecin)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Tczew)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Tułowice)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Tychy)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Warszawa)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Wieluń)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Więcbork)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Wolsztyn)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Wrocław)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Wronki)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Zabrze)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Zakopane)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Zduny)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Zielona Góra)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Ząbki)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Łomża)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Łódź)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Świątniki Górne)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Świętochłowice)</th>\n",
              "      <th>group_Work abroad - join to find well paid work and enjoy the experience (Żory)</th>\n",
              "      <th>group_World Weightlifting Championships</th>\n",
              "      <th>group_Xbox , Playstation, Wii - console fans</th>\n",
              "      <th>group_Young, fit and healthy - active livestyle = healthy lifestyle.</th>\n",
              "      <th>group_ZTM Warsaw</th>\n",
              "      <th>group_alternative medicine - Hypnosis and bioenergotheraphy</th>\n",
              "      <th>group_ham cooker - recipes</th>\n",
              "      <th>group_instrumental music - the unheard and undiscovered</th>\n",
              "      <th>group_muscle, strength  and vascularity - What every bodybuilder should know</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1973</td>\n",
              "      <td>152</td>\n",
              "      <td>337</td>\n",
              "      <td>29</td>\n",
              "      <td>146</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1991</td>\n",
              "      <td>301</td>\n",
              "      <td>251</td>\n",
              "      <td>14</td>\n",
              "      <td>209</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1994</td>\n",
              "      <td>413</td>\n",
              "      <td>49</td>\n",
              "      <td>34</td>\n",
              "      <td>287</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1988</td>\n",
              "      <td>279</td>\n",
              "      <td>217</td>\n",
              "      <td>20</td>\n",
              "      <td>226</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1992</td>\n",
              "      <td>346</td>\n",
              "      <td>217</td>\n",
              "      <td>11</td>\n",
              "      <td>167</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2176 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  ...  group_muscle, strength  and vascularity - What every bodybuilder should know\n",
              "0        0  ...                                                  0                           \n",
              "1        1  ...                                                  0                           \n",
              "3        3  ...                                                  0                           \n",
              "4        4  ...                                                  0                           \n",
              "6        6  ...                                                  0                           \n",
              "\n",
              "[5 rows x 2176 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_W4qf5LM9TP"
      },
      "source": [
        "This dataframe has a different number of columns than before due to the different set of hobbies and groups that users belong to. It is needed to add columns that are missing from this dataframe and remove additional columns that didn't exist previously in order to have exactly the same set of columns as in the dataframe used for the model. New columns will be filled with '0'. Additional column will be dropped because the model doesn't know what to do with hobbies or groups that didn't exist in the fitting data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucbcppS4OSWd",
        "outputId": "f21305ff-66bc-46ca-d756-f0042935dd16"
      },
      "source": [
        "missing_col = df_model.columns.difference(df.columns)\n",
        "for col in missing_col:\n",
        "  df[col] = 0\n",
        "additional_col = df.columns.difference(df_model.columns)\n",
        "df.drop(labels=additional_col.tolist(), axis=1, inplace=True)\n",
        "df.drop(labels='target', axis=1, inplace=True)\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1452 entries, 0 to 1999\n",
            "Columns: 3520 entries, user_id to group_Work abroad - join to find well paid work and enjoy the experience (Żyrardów)\n",
            "dtypes: float64(1), int16(2), int64(3514), int8(3)\n",
            "memory usage: 39.0 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOeDe7ZAQvSD"
      },
      "source": [
        "Now the model can be used to predict target value for the test dataset. As a result one gets a list of probabilities for each user included in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo4NpOUtQ11S",
        "outputId": "43116e5e-b905-4557-c445-ea822d2f1ca9"
      },
      "source": [
        "test_features = df.copy()\n",
        "test_predictions = model.predict(test_features)\n",
        "print(test_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.8932862e-10]\n",
            " [0.0000000e+00]\n",
            " [0.0000000e+00]\n",
            " ...\n",
            " [5.2984547e-16]\n",
            " [2.9828572e-01]\n",
            " [9.4054925e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87JsqknSRqgb"
      },
      "source": [
        "Finally, it is possible to prepare a scored test file. For the rows that were skipped in the prediction phase due to missing information I am going to assume the target variable is '0'. For the rest of the users I will use predicted probability and set a target value by rounding probability to the nearest integer value. Then, the output file will be saved as a CSV in a desired format consisting of 3 columns: 'user_id', 'probability_of_one', and 'target'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFJ6PEB4SD8W"
      },
      "source": [
        "df_score = pd.DataFrame(columns=['user_id', 'probability_of_one', 'target'])\n",
        "user_pred = 0\n",
        "for user in range(df_csv.shape[0]):\n",
        "  if user in df['user_id']:\n",
        "    df_score =df_score.append({'user_id': user, 'probability_of_one': test_predictions[user_pred][0], 'target': np.around(test_predictions[user_pred][0])}, ignore_index=True)\n",
        "    user_pred += 1\n",
        "  else:\n",
        "    df_score =df_score.append({'user_id': user, 'probability_of_one': 0., 'target': 0.}, ignore_index=True)\n",
        "df_score = df_score.astype({'user_id': int, 'target': int})\n",
        "df_score.head()\n",
        "df_score.to_csv('test.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxaM9uUmvMzi"
      },
      "source": [
        "# Findings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7trQqYfm14xJ"
      },
      "source": [
        "During the process of analysis of the data it was discovered that some information is missing. It is not always clear what to do with missing data, so several assumptions were made. \n",
        "\n",
        "Moreover, it would require more detailed analysis of the input data to discover what part of data is useful for the model and which part could be removed. One of the possible solutions would be to use heatmaps to find correlations between data. A detailed investigation of the data would be necessary to determine what should be used as an input for the model.\n",
        "\n",
        "It was also discovered that the model works well predicting a lack of interest in gym subscription, but it works much worse when trying to find people interested in the subscription. This is most probably connected with the fact that the model can still be tuned in a better way. A further investigation of a possible layer settings of the model should also be tested to find a better solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw54fzzcvOLg"
      },
      "source": [
        "# Limitations of the Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40uwYRkP16UW"
      },
      "source": [
        "This approach has various limitations. First of all, it is assumed that the model will be used to predict interest for users with similar hobbies and belonging to similar groups. In practice this may not be the case.\n",
        "\n",
        "Furthermore, the approach of extracting hobbies and groups into separate columns generated more than three thousand columns in the dataset. This value might get even bigger when using a different dataset as an input file, because one can produce even more columns and run out of available memory at some point.\n",
        "\n",
        "The model was also built and tested without any information from the JSON file at all in the first attempt - this means that no information about groups was included. This solution reduced the number of columns significantly and the model had a higher efficacy of predicting users interested in gym subscription. On the other hand, it had lower efficacy of predicting users not interested in the subscription and a slightly lower efficiency overall. It depends on the approach, but one can focus on maximizing the overall efficiency, the efficiency for users interested in the subscription, or the efficiency of users not interested in the subscription."
      ]
    }
  ]
}